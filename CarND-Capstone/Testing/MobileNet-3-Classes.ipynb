{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "img_root_folder = \"./TLdataset02\"\n",
    "def load_images(folder, label):\n",
    "    images = []\n",
    "    image_folder = \"{}/{}\".format(img_root_folder, folder)\n",
    "    image_names = os.listdir(image_folder)\n",
    "    for image_name in image_names:\n",
    "        image = cv2.imread(image_folder + '/' + image_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image,(224,224))\n",
    "        images.append(image)\n",
    "\n",
    "    labels = [label for x in range(len(images))]\n",
    "    return zip(images, labels)\n",
    "\n",
    "labeled_data = []\n",
    "green = load_images(\"green\", 2)\n",
    "labeled_data.extend(green)\n",
    "red = load_images(\"red\", 0)\n",
    "labeled_data.extend(red)\n",
    "yellow = load_images(\"yellow\", 1)\n",
    "labeled_data.extend(yellow)\n",
    "#unknown = load_images(\"unknown\", 3) # JUST TO HAVE NO GAPS, IS ACTUALLY 4 IN THE MESSAGE TrafficLight \n",
    "#labeled_data.extend(unknown)\n",
    "\n",
    "np.random.shuffle(labeled_data)\n",
    "# splits the entire set into training and test data\n",
    "train_samples, test_samples = train_test_split(labeled_data, test_size=0.1)\n",
    "# the training data is split further into training and validation\n",
    "train_samples, validation_samples = train_test_split(train_samples, test_size=0.2)\n",
    "\n",
    "X_train, y_train = zip(*train_samples) \n",
    "X_valid, y_valid = zip(*validation_samples) \n",
    "X_test, y_test = zip(*test_samples) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(X_train)\n",
    "n_validation = len(X_valid)\n",
    "n_test = len(X_test)\n",
    "\n",
    "# Here is assumed, that all images are of the same size\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# Assuming that each label occurs at least once in each set.\n",
    "# Otherwise the data split training/validation/test would have been insufficient\n",
    "assert( (len(np.unique(y_train)) == len(np.unique(y_valid))) and (len(np.unique(y_train)) == len(np.unique(y_test))) )\n",
    "n_classes = len(np.unique(y_valid))\n",
    "\n",
    "print(\"Number of examples =\", len(labeled_data))\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_validation)\n",
    "print(\"Number of test examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)\n",
    "#print(\"y_train = \", y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the input data to tensors\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from tqdm import tqdm\n",
    "def image_to_tensor(img):\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "def images_to_tensor(imgs):\n",
    "    list_of_tensors = [image_to_tensor(img) for img in imgs]\n",
    "    return np.vstack(list_of_tensors)\n",
    "# to tensors and normalize it\n",
    "train_tensors = images_to_tensor(X_train).astype('float32')/255\n",
    "valid_tensors = images_to_tensor(X_valid).astype('float32')/255\n",
    "test_tensors = images_to_tensor(X_test).astype('float32')/255\n",
    "\n",
    "print(\"train_tensors shape = \", train_tensors.shape)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=n_classes)\n",
    "y_valid = to_categorical(y_valid, num_classes=n_classes)\n",
    "y_test = to_categorical(y_test, num_classes=n_classes)\n",
    "\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load keras libraies and load the MobileNet model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "\n",
    "#model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (224, 224, 3))\n",
    "model = applications.mobilenet.MobileNet(input_shape = image_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the custom layers\n",
    "x = model.output\n",
    "#x = Flatten()(x)\n",
    "#x = Dense(4096, activation=\"relu\")(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final modal\n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = 'rmsprop', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and save best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model.\n",
    "epochs = 20\n",
    "batch_size = 16\n",
    "\n",
    "model_filepath = 'saved_models/model.MobileNet-3-classes.h5'\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=model_filepath, \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model_final.fit(train_tensors, y_train, \n",
    "          validation_data=(valid_tensors, y_valid),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final test\n",
    "## Should only be run once after model architecture is settled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "\n",
    "del model\n",
    "with CustomObjectScope({'relu6': applications.mobilenet.relu6,'DepthwiseConv2D': applications.mobilenet.DepthwiseConv2D}):\n",
    "    model = load_model('saved_models/weights.best.MobileNet.h5')\n",
    "\n",
    "# get index of predicted signal sign for each image in test set\n",
    "signal_predictions = [model.predict(np.expand_dims(tensor, axis=0)) for tensor in test_tensors]\n",
    "# print out test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(signal_predictions)==y_test)/len(signal_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
