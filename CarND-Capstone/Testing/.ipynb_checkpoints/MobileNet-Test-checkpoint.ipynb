{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# load keras libraies and load the MobileNet model\n",
    "from keras.models import Model\n",
    "from keras import applications\n",
    "from keras.models import load_model\n",
    "\n",
    "# load the trained model\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "\n",
    "model_filepath = 'saved_models/model.MobileNet-3-classes.h5'\n",
    "n_classes = 3\n",
    "\n",
    "#del model\n",
    "with CustomObjectScope({'relu6': applications.mobilenet.relu6,'DepthwiseConv2D': applications.mobilenet.DepthwiseConv2D}):\n",
    "    model = load_model(model_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images\n",
    "## NOTE: The classification is red = [1 0 0], green = [0 0 1] and yellow = [0 1 0], so the red light images must be in a folder which comes alphabetically before the yellow folder and the yellow folder name must be alphabetically before the green one!\n",
    "Example:\n",
    "red light images in sub-folder \"0.red\"\n",
    "\n",
    "yellow light images in sub-folder \"1.yellow\"\n",
    "\n",
    "green light images in sub-folder \"2.green\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# define function to load the train, test datasets\n",
    "def load_dataset(path):\n",
    "#    data = load_files(path, categories=['red', 'yellow', 'green'])\n",
    "    data = load_files(path)\n",
    "    X = np.array(data['filenames'])\n",
    "    y = np_utils.to_categorical(np.array(data['target']), n_classes)\n",
    "    print(data['target'])\n",
    "    print(data['target_names'])\n",
    "    return X, y\n",
    "\n",
    "# load the train, test dataset\n",
    "X_test, y_test = load_dataset('test_data')\n",
    "# load the list of signal names\n",
    "signal_names = [item[10:-1] for item in sorted(glob(\"test_data/*/\"))]\n",
    "\n",
    "print('Shape of X_test: ', X_test.shape)\n",
    "print('Shape of y_test: ', y_test.shape)\n",
    "print('There are %d total images' % X_test.shape[0])\n",
    "print('There are %d kinds of signals:' % y_test.shape[1])\n",
    "print('\\t\\t\\t',signal_names)\n",
    "\n",
    "# transform the input data to tensors\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "# to tensors and normalize it\n",
    "test_tensors = paths_to_tensor(X_test).astype('float32')/255\n",
    "\n",
    "# get index of predicted signal sign for each image in test set\n",
    "signal_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "# print out test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(signal_predictions)==np.argmax(y_test, axis=1))/len(signal_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_tensors.shape)\n",
    "img = test_tensors[0]\n",
    "print(img.shape)\n",
    "# get index of predicted signal sign for each image in test set\n",
    "signal_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "print(signal_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "imageCount = X_test.shape[0]\n",
    "rows = math.ceil(math.sqrt())\n",
    "\n",
    "imageDict = {}\n",
    "# gets the sign names for the labels\n",
    "imageDict[0] = 'red'\n",
    "imageDict[1] = 'yellow'\n",
    "imageDict[2] = 'green'\n",
    "\n",
    "images = []\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "\n",
    "for index in range(imageCount):\n",
    "    plt.subplot(8, 8, index+1)\n",
    "    plt.title(\"{}, p: {}\".format(imageDict[np.argmax(y_test[index])], imageDict[signal_predictions[index]]))\n",
    "    plt.axis('off')\n",
    "    image = test_tensors[index]\n",
    "    plt.imshow(image)\n",
    "    images.append(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
